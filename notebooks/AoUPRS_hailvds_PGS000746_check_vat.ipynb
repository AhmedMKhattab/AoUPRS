{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightgreen; padding: 10px; font-size: 24px;\">\n",
    "    \n",
    "__PRS Calculator:__ Hail VDS   \n",
    "    \n",
    "Check Variant Annotation Table\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightgrey; padding: 10px;; font-size: 18px;\">  \n",
    "    \n",
    "__Author:__ Ahmed Khattab  \n",
    "        __Scripps Research__\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:lightblue; padding: 10px; font-size: 16px;\"> \n",
    "    \n",
    "__Introduction__\n",
    "\n",
    "In this notebook, we will demonstrate how to check the callset (VAT) for how many present and missing variants in your weight table.\n",
    "\n",
    "\n",
    "__Using VAT__ \n",
    "\n",
    "VAT is a structured table containing functional annotations for the variants detected in the srWGS dataset. \n",
    "    \n",
    "__Resources used?__   \n",
    "\n",
    "\n",
    "Cost when running: $0.73 per hour  \n",
    "\n",
    "Main node: 4CPUs, 15GB RAM, 150 GB Disk  \n",
    "Workers (2): 4CPUs, 15GB RAM, 150GB Disk   \n",
    "\n",
    "Time and Cost:  __$0.05 / ~4 min__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T16:34:53.461248Z",
     "iopub.status.busy": "2023-10-06T16:34:53.460776Z",
     "iopub.status.idle": "2023-10-06T16:34:53.473497Z",
     "shell.execute_reply": "2023-10-06T16:34:53.472912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2024-07-01\n",
      "Start time: 22:09:31\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Record the start time\n",
    "current_date = start_time.date()\n",
    "current_time = start_time.time()\n",
    "\n",
    "# Format the current date\n",
    "formatted_start_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Format the current time\n",
    "formatted_start_time = current_time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Print the formatted date and time separately\n",
    "print(\"Start date:\", formatted_start_date)\n",
    "print(\"Start time:\", formatted_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/jupyter/.local/lib/python3.10/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ruby\n",
    "# Install tabix if not already installed\n",
    "pip install --user pytabix\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-16T20:09:11.806426Z",
     "iopub.status.busy": "2023-09-16T20:09:11.805899Z",
     "iopub.status.idle": "2023-09-16T20:09:12.059189Z",
     "shell.execute_reply": "2023-09-16T20:09:12.058207Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import gcsfs\n",
    "import multiprocessing\n",
    "import ast\n",
    "import concurrent.futures\n",
    "import glob\n",
    "import tabix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = os.getenv(\"WORKSPACE_BUCKET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check SNP in VAT\n",
    "- Check which variants in your score exist in the callset before using VDS for scores calculation\n",
    "- Find more: https://support.researchallofus.org/hc/en-us/articles/22522829338260-Hotfix-released-for-v7-Variant-Annotation-Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download VAT to Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/vat/vat_complete.bgz.tsv.gz\r\n",
      "gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/vat/vat_complete_v7.1.bgz.tsv.gz\r\n"
     ]
    }
   ],
   "source": [
    "# VAT can be found here\n",
    "!gsutil -m -u $GOOGLE_PROJECT ls gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/vat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"background-color: grey;\">\n",
    "    <ul>\n",
    "        <li>VAT has many fields but we only need chr, position, and both alleles to match with variants in our weight table.</li>\n",
    "        <li>The code below will help you download the VAT file but we already completeted that step elsewhere so will be using it directly.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```ruby\n",
    "# Use a TERMINAL to download and tabix the VAT\n",
    "\n",
    "# Copy the file to locally:\n",
    "gsutil -u $GOOGLE_PROJECT cp gs://fc-aou-datasets-controlled/v7/wgs/short_read/snpindel/aux/vat/vat_complete_v7.1.bgz.tsv.gz > vat_complete_v7.1.bgz.tsv.gz\n",
    "\n",
    "\n",
    "# Process the local file\n",
    "mkdir tmp\n",
    "gunzip -c vat_complete_v7.1.bgz.tsv.gz | \\\n",
    "# Only keep the 4 needed cols; chr, pos, alt, ref\n",
    "  awk -F'\\t' '{print $3\"\\t\"$4\"\\t\"$5\"\\t\"$6}' | \\\n",
    "  sed 's~chr~~g' | \\\n",
    "  sort -u -S 5G -T /tmp/ | \\\n",
    "  bgzip -@ 16 > chr_pos_ref_alt.vat_v7.1.tsv.bgz\n",
    "\n",
    "# Create tabix file\n",
    "tabix -S 1 -s 3 -b 4 -e 4 chr_pos_ref_alt.vat_v7.1.tsv.bgz\n",
    "\n",
    "# The local files get deleted when you delete the \"Hail Genomic Analysis\" environment. Make sure to copy them to the cloud.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://fc-secure-e5684327-e720-41ed-979a-b9ae6477b844/allofus_phenotypes/people_with_WGS_EHR_020524/cad/chr_pos_ref_alt.vat_v7.1.tsv.bgz to file:///home/jupyter/chr_pos_ref_alt.vat_v7.1.tsv.bgz\n",
      "  Completed files 1/1 | 2.8GiB/2.8GiB | 57.3MiB/s                              \n",
      "\n",
      "Average throughput: 136.0MiB/s\n",
      "Copying gs://fc-secure-e5684327-e720-41ed-979a-b9ae6477b844/allofus_phenotypes/people_with_WGS_EHR_020524/cad/chr_pos_ref_alt.vat_v7.1.tsv.bgz.tbi to file:///home/jupyter/chr_pos_ref_alt.vat_v7.1.tsv.bgz.tbi\n",
      "  Completed files 1/1 | 2.3MiB/2.3MiB                                          \n",
      "\n",
      "Average throughput: 146.7MiB/s\n"
     ]
    }
   ],
   "source": [
    "# download files locally (will be deleted when you delete the current Hail enviornment)\n",
    "!gcloud storage cp {bucket}/allofus_phenotypes/people_with_WGS_EHR_020524/cad/chr_pos_ref_alt.vat_v7.1.tsv.bgz /home/jupyter\n",
    "!gcloud storage cp {bucket}/allofus_phenotypes/people_with_WGS_EHR_020524/cad/chr_pos_ref_alt.vat_v7.1.tsv.bgz.tbi /home/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vat_fp = \"/home/jupyter/chr_pos_ref_alt.vat_v7.1.tsv.bgz\"\n",
    "vat_tb = tabix.open(vat_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_allele_in_tabix(row, vat_tb):\n",
    "    try:\n",
    "        records = vat_tb.query(str(row['chr']), row['bp'] - 1, row['bp'])\n",
    "        for record in records:\n",
    "            # Assuming the structure of record is ['chr', 'bp', 'ref', 'alt']\n",
    "            if row['effect_allele'] in record[2:4]:  # Checking if effect_allele is in ref/alt\n",
    "                return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying tabix: {e}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/\"\n",
    "query_dir = \"/home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/vat_query\"\n",
    "check_dir = \"/home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/vat_check\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1938, 9) read: /home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores//PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv\n",
      "3 SNPs not found in VAT\n",
      "(1938, 10) saved: /home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/vat_query/PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv\n",
      "(1935, 9) saved: /home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/vat_check/PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv\n",
      "\n",
      "Execution time: 35.2281973361969 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    " \n",
    "for pgs_fp in glob.glob(f'{input_dir}/PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv'): \n",
    "    pgs_df_name = pgs_fp.split(\"/\")[-1].split(\".\")[0]  # Specify the name of the DataFrame\n",
    "    pgs_df = pd.read_csv(pgs_fp, dtype={\"weight\": \"str\"})\n",
    "    print(f\"{pgs_df.shape} read: {pgs_fp}\")\n",
    "    \n",
    "    # Assuming `check_allele_in_tabix` is a function defined elsewhere\n",
    "    pgs_df['AoU'] = pgs_df.apply(check_allele_in_tabix, vat_tb=vat_tb, axis=1)\n",
    "    print(f\"{pgs_df['AoU'].value_counts().get(False, 0)} SNPs not found in VAT\")\n",
    "    \n",
    "    vat_pgs_fp = f\"{query_dir}/{pgs_fp.split('/')[-1]}\"\n",
    "    pgs_df.to_csv(vat_pgs_fp, index=False)\n",
    "    print(f\"{pgs_df.shape} saved: {vat_pgs_fp}\")\n",
    "    \n",
    "    vat_check_pgs_df = pgs_df.loc[pgs_df['AoU'] == True].drop(columns=[\"AoU\"])\n",
    "    vat_check_pgs_fp = f\"{check_dir}/{pgs_fp.split('/')[-1].replace(input_dir.split('_')[-1], 'vat_check')}\"\n",
    "    vat_check_pgs_df.to_csv(vat_check_pgs_fp, index=False)\n",
    "    print(f\"{vat_check_pgs_df.shape} saved: {vat_check_pgs_fp}\\n\")\n",
    "    \n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][117.5 KiB/117.5 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/117.5 KiB.                                    \n",
      "Copying file:///home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/vat_check/PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][117.3 KiB/117.3 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/117.3 KiB.                                    \n",
      "Copying file:///home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/vat_query/PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][127.0 KiB/127.0 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/127.0 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# Always save files to the cloud as they get deleted with the deletion of the environment.\n",
    "!gsutil -m cp /home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv {bucket}/AoUPRS/AoUPRS_hail_vds/\n",
    "!gsutil -m cp /home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/vat_check/PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv {bucket}/AoUPRS/AoUPRS_hail_vds/vat_check/\n",
    "!gsutil -m cp /home/jupyter/workspaces/duplicateoftype2diabetesriskprediction/prs_scores/vat_query/PGS000746_Gola_D_PRS_1940_Coronary_artery_disease_Circ_Genom_Precis_Med_2020.GRCh37_to_GRCh38.csv {bucket}/AoUPRS/AoUPRS_hail_vds/vat_query/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End date: 2024-07-01\n",
      "End time: 22:12:10\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "# Get the current date and time again\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Record the end time\n",
    "current_date = end_time.date()\n",
    "current_time = end_time.time()\n",
    "\n",
    "# Format the current date\n",
    "formatted_end_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Format the current time\n",
    "formatted_end_time = current_time.strftime(\"%H:%M:%S\")\n",
    "\n",
    "# Print the formatted end date and time separately\n",
    "print(\"End date:\", formatted_end_date)\n",
    "print(\"End time:\", formatted_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
